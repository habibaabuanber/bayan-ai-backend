# # from fastapi import FastAPI

# # app = FastAPI()

# # @app.get("/")
# # def root():
# #     return {"message": "Backend is working âœ…"}
# from fastapi import FastAPI
# from pydantic import BaseModel
# from typing import List, Dict, Any
# import numpy as np
# import json
# from pathlib import Path
# from sklearn.metrics.pairwise import cosine_similarity
# from langdetect import detect
# from openai import OpenAI
# import requests

# # ------------------- CONFIG -------------------

#  # Ø­Ø·ÙŠ Ù…ÙØªØ§Ø­Ùƒ Ù‡Ù†Ø§
# BOOKS_FILE = "books_dataset_enriched.jsonl"
# EMB_FILE = "books_embeddings.npy"
# META_FILE = "books_metadata.json"
# EMBED_MODEL = "text-embedding-3-small"
# TOP_K = 4

# # ------------------- LOAD DATA -------------------
# def load_books(path: str):
#     return [json.loads(line) for line in open(path, "r", encoding="utf-8")]

# def load_embeddings():
#     embeddings = np.load(EMB_FILE)
#     with open(META_FILE, "r", encoding="utf-8") as f:
#         metas = json.load(f)
#     return embeddings, metas

# books_raw = load_books(BOOKS_FILE)[:200]
# embeddings, metas = load_embeddings()

# # ------------------- SEARCH FUNCTION -------------------
# def embed_text(text: str):
#     resp = client.embeddings.create(model=EMBED_MODEL, input=text)
#     return resp.data[0].embedding

# def find_top_k(query: str, k: int = TOP_K):
#     query_emb = np.array(embed_text(query), dtype=np.float32).reshape(1, -1)
#     sims = cosine_similarity(query_emb, embeddings)[0]
#     idx = np.argsort(sims)[::-1][:k]
#     results = []
#     for i in idx:
#         m = metas[int(i)].copy()
#         m["_score"] = float(sims[int(i)])
#         results.append(m)
#     return results

# # ------------------- FASTAPI APP -------------------
# app = FastAPI()
# conversation_history: List[Dict] = []
# class ChatRequest(BaseModel):
#     message: str
#     # history: List[Dict[str, str]] = []  âœ… Ù†Ø´ÙŠÙ„ Ø¯Ù‡

# @app.get("/")
# def root():
#     return {"message": "Backend is working âœ…"}

# @app.post("/chat")
# def chat(req: ChatRequest):
#     user_text = req.message

#     # 1) Ø®Ø²Ù‘Ù† Ø±Ø³Ø§Ù„Ø© Ø§Ù„ÙŠÙˆØ²Ø± ÙÙŠ Ø§Ù„Ù€ history
#     conversation_history.append({"role": "user", "content": user_text})

#     # Auto detect language
#     try:
#         lang = "ar" if detect(user_text) == "ar" else "en"
#     except:
#         lang = "en"

#     # Ù†Ø­Ø¯Ø¯ Ù‡Ù„ Ù†Ø±Ø´Ø­ ÙˆÙ„Ø§ Ù„Ø³Ù‡ Ù‡Ù†Ø³Ø£Ù„
#     trigger_terms = ["recommend", "suggest", "surprise", "Ø§Ù‚ØªØ±Ø­", "Ø±Ø´Ø­", "Ù†ØµÙŠØ­Ø©"]
#     need_recommend = any(t in user_text.lower() for t in trigger_terms) or len(conversation_history) >= 3

#     if need_recommend:
#         # Build full preference string Ù…Ù† Ø§Ù„Ù€ history ÙƒÙ„Ù‡
#         full_query = " ; ".join([h["content"] for h in conversation_history if h["role"] == "user"])

#         best = find_top_k(full_query, k=TOP_K)

#         # Ø­Ø¶Ù‘Ø±ÙŠ ÙˆØµÙ Ø§Ù„ÙƒØªØ¨
#         books_block = ""
#         for b in best:
#             books_block += f"Title: {b['title']}\nAuthor: {b.get('authors','')}\nSummary: {b.get('summary','')}\n\n"

#         prompt = f"""
# You are a friendly librarian. The user likes: {full_query}.
# Explain in {lang} very briefly in just two or three sentences why these books would match them:
# {books_block}
# """

#         resp = client.chat.completions.create(
#             model="gpt-4o-mini",
#             messages=[{"role": "user", "content": prompt}]
#         )

#         reply = resp.choices[0].message.content

#         # 2) Ø®Ø²Ù‘Ù† Ø±Ø¯ Ø§Ù„Ø¨ÙˆØª
#         conversation_history.append({"role": "assistant", "content": reply})

#         return {"reply": reply, "books": best}

#     else:
#         # Ù„Ø³Ù‡ Ø¨Ø¯Ø±ÙŠ â€” Ù†Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ Ù…ØªØªØ§Ø¨Ø¹
#         history_text = "\n".join([f"{h['role']}: {h['content']}" for h in conversation_history])
#         print("HISTORY: ",history_text)
#         prompt = f"""
# You are a curious librarian. Ask ONE short question that follows logically based on the user's last answer, to recommend a book later.
# Conversation so far:
# {history_text}
# Respond in {lang}.
# """

#         resp = client.chat.completions.create(
#             model="gpt-4o-mini",
#             messages=[{"role": "user", "content": prompt}]
#         )

#         reply = resp.choices[0].message.content

#         # Ø®Ø²Ù‘Ù† Ø±Ø¯ Ø§Ù„Ø¨ÙˆØª
#         conversation_history.append({"role": "assistant", "content": reply})

#         return {"reply": reply, "books": []}
from fastapi import FastAPI
from pydantic import BaseModel
import numpy as np
import json
from pathlib import Path
from sklearn.metrics.pairwise import cosine_similarity
from langdetect import detect
from openai import OpenAI
import requests
from dotenv import load_dotenv
from typing import List, Dict, Any, Optional
import uuid
import time



# ------------------- CONFIG -------------------

import os
from dotenv import load_dotenv

load_dotenv()  # Load .env file

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_BOOKS_API_KEY = os.getenv("GOOGLE_BOOKS_API_KEY", "")  # optional

client = OpenAI(api_key=OPENAI_API_KEY)

BOOKS_FILE = "books_dataset_enriched.jsonl"
EMB_FILE = "books_embeddings.npy"
META_FILE = "books_metadata.json"
EMBED_MODEL = "text-embedding-3-small"
TOP_K = 4

# ------------------- LOAD DATA -------------------
def load_books(path: str):
    return [json.loads(line) for line in open(path, "r", encoding="utf-8")]

def load_embeddings():
    embeddings = np.load(EMB_FILE)
    with open(META_FILE, "r", encoding="utf-8") as f:
        metas = json.load(f)
    return embeddings, metas

# books_raw = load_books(BOOKS_FILE)[:200]
# embeddings, metas = load_embeddings()
# ------------ LOAD MULTIPLE DATASETS ------------
def load_multiple_jsonl(paths: List[str]):
    all_books = []
    for p in paths:
        print(f"Loading books from: {p}")
        all_books.extend(load_books(p))
    return all_books

def load_multiple_embeddings(emb_paths: List[str], meta_paths: List[str]):
    all_embs = []
    all_metas = []

    for emb_file, meta_file in zip(emb_paths, meta_paths):
        print(f"Loading embeddings from: {emb_file}")
        embs = np.load(emb_file)
        all_embs.append(embs)

        print(f"Loading metadata from: {meta_file}")
        with open(meta_file, "r", encoding="utf-8") as f:
            metas = json.load(f)
        all_metas.extend(metas)

    # concatenate embeddings vertically
    final_embs = np.vstack(all_embs)
    return final_embs, all_metas


# ---------- LOAD DATASETS ----------
books_raw = load_multiple_jsonl([
    "books_dataset_enriched.jsonl",
    "second_dataset_clean.jsonl"
])

embeddings, metas = load_multiple_embeddings(
    ["books_embeddings.npy", "second_dataset_embeddings.npy"],
    ["books_metadata.json", "second_dataset_metadata.json"]
)

# ------------------- HELPERS -------------------
def embed_text(text: str):
    resp = client.embeddings.create(model=EMBED_MODEL, input=text)
    return resp.data[0].embedding

def find_top_k(query: str, k: int = TOP_K):
    query_emb = np.array(embed_text(query), dtype=np.float32).reshape(1, -1)
    sims = cosine_similarity(query_emb, embeddings)[0]
    idx = np.argsort(sims)[::-1][:k]
    results = []
    for i in idx:
        m = metas[int(i)].copy()
        m["_score"] = float(sims[int(i)])
        results.append(m)
    return results
# def find_top_k(query: str, user_lang: str = None, k: int = TOP_K):
#     query_emb = np.array(embed_text(query), dtype=np.float32).reshape(1, -1)
#     sims = cosine_similarity(query_emb, embeddings)[0]
#     idx = np.argsort(sims)[::-1]
#     results = []
#     for i in idx:
#         m = metas[int(i)].copy()
#         if user_lang and m.get("language") != user_lang:
#             continue
#         m["_score"] = float(sims[int(i)])
#         results.append(m)
#         if len(results) >= k:
#             break
#     return results

def get_cover_google(isbn: str):
    if not isbn:
        return None
    try:
        url = f"https://www.googleapis.com/books/v1/volumes?q=isbn:{isbn}"
        r = requests.get(url, timeout=6)
        data = r.json()
        items = data.get("items")
        if items:
            vol = items[0].get("volumeInfo", {})
            imgs = vol.get("imageLinks", {})
            for k in ("extraLarge", "large", "medium", "small", "thumbnail"):
                if imgs.get(k):
                    return imgs.get(k)
        return None
    except:
        return None

def get_cover_openlibrary(isbn: str):
    if not isbn:
        return None
    return f"https://covers.openlibrary.org/b/isbn/{isbn}-L.jpg"

import requests
import urllib.parse

def get_cover_by_title(title: str, authors: str = ""):
    try:
        clean_title = title.strip().replace('"', '').replace(':', '')
        query = f"intitle:{clean_title}"
        
        if authors:
            first_author = authors.split('/')[0].split(',')[0].strip()
            clean_author = first_author.replace('"', '').replace(':', '')
            query += f" inauthor:{clean_author}"
        
        encoded_query = urllib.parse.quote(query)
        url = f"https://www.googleapis.com/books/v1/volumes?q={encoded_query}&maxResults=3"
        
        print(f"ğŸ” Searching for cover: {query}")
        
        r = requests.get(url, timeout=10)
        data = r.json()
        
        items = data.get("items", [])
        print(f"ğŸ“š Found {len(items)} items")
        
        if items:
            # Ù†Ø¬Ø±Ø¨ ÙƒÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¹Ø´Ø§Ù† Ù†Ù„Ø§Ù‚ÙŠ ÙˆØ§Ø­Ø¯Ø© ÙÙŠÙ‡Ø§ ØµÙˆØ±Ø©
            for item in items:
                vol = item.get("volumeInfo", {})
                imgs = vol.get("imageLinks", {})
                
                # Ù†Ø·Ø¨Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙƒØªØ§Ø¨ Ù„Ù„Øªdebug
                found_title = vol.get('title', '')
                found_authors = vol.get('authors', [])
                print(f"   ğŸ“– Found: '{found_title}' by {found_authors}")
                
                for k in ("extraLarge", "large", "medium", "small", "thumbnail"):
                    if imgs.get(k):
                        print(f"   âœ… Found cover: {imgs.get(k)}")
                        return imgs.get(k)
        
        print("   âŒ No covers found")
        return None
        
    except Exception as e:
        print(f"   âŒ Error in get_cover_by_title: {e}")
        return None
    
def ensure_cover(book: Dict[str, Any]):
    if book.get("cover_url"):
        return book["cover_url"]
    
    isbn = book.get("isbn","")
    cover = None
    
    if isbn and isbn != "N/A" and isbn != "null":
        cover = get_cover_google(isbn) or get_cover_openlibrary(isbn)
        if cover:
            print(f"âœ… Found cover by ISBN: {isbn}")
    
    if not cover:
        cover = get_cover_by_title(book.get('title', ''), book.get('authors', ''))
        if cover:
            print(f"âœ… Found cover by title: {book.get('title', '')}")
    
    book["cover_url"] = cover
    return cover

# ------------------- FASTAPI APP -------------------
app = FastAPI()
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Ù…Ù…ÙƒÙ† Ø¨Ø¹Ø¯ÙŠÙ† ØªØ¹Ù…Ù„ÙŠÙ‡Ø§ Ù„Ø¯ÙˆÙ…ÙŠÙ† Ù…Ø­Ø¯Ø¯
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# @app.get("/")
# def root():
#     return {"message": "Backend is working âœ…"}
@app.get("/")
def health_check():
    return {"status": "ok", "service": "Bayan AI Librarian"}

@app.get("/health")
def health():
    return {"status": "healthy"}

conversation_history: List[Dict[str, Any]] = []
user_prefs: Dict[str, Any] = {}
# SESSION store in-memory
SESSIONS: Dict[str, Dict[str, Any]] = {}
# session structure:
# SESSIONS[session_id] = {
#   "conversation_history": [{"role":"user"/"assistant", "content": "..."}],
#   "user_prefs": {"pref_1": "...", ...},
#   "recommended": False,
#   "last_active": timestamp
# }

SESSION_TTL_SECONDS = 60 * 60  

class ChatRequest(BaseModel):
    message: Optional[str] = None
    session_id: Optional[str] = None
    reset: Optional[bool] = False

def create_session() -> str:
    sid = str(uuid.uuid4())
    SESSIONS[sid] = {
        "conversation_history": [],
        "user_prefs": {},
        "recommended": False,
        "last_active": time.time()
    }
    return sid

def get_session(session_id: Optional[str]) -> str:
    # if no session_id provided or invalid, create new
    if not session_id or session_id not in SESSIONS:
        return create_session()
    return session_id

def touch_session(session_id: str):
    if session_id in SESSIONS:
        SESSIONS[session_id]["last_active"] = time.time()

def clear_session(session_id: str):
    # reinitialize session (keep same id) or remove entirely
    if session_id in SESSIONS:
        SESSIONS[session_id] = {
            "conversation_history": [],
            "user_prefs": {},
            "recommended": False,
            "last_active": time.time()
        }

def sweep_expired_sessions():
    now = time.time()
    to_delete = [sid for sid, s in SESSIONS.items() if now - s.get("last_active", 0) > SESSION_TTL_SECONDS]
    for sid in to_delete:
        SESSIONS.pop(sid, None)

def normalize_language(lang):
    lang = str(lang).lower().strip()
    if lang in ['eng', 'english', 'en-us', 'en_us', 'en']:
        return 'en' 
    elif lang in ['ar', 'ara', 'arabic']:
        return 'ar'
    return lang


@app.post("/chat")
def chat(req: ChatRequest):
    # optional: sweep expired sessions occasionally
    sweep_expired_sessions()

    print("\nğŸŸ¢ --- Incoming Request ---")
    print(f"Reset: {req.reset}")
    print(f"Session ID: {req.session_id}")
    print(f"Message: {req.message}")
    print("----------------------------\n")

    # If user asked to reset/new chat, create a fresh session
    if req.reset:
        new_sid = create_session()
        starter = "New chat started. Hi! What kind of books are you in the mood for?"
        print(f"ğŸŸ¡ [New Session Created] session_id={new_sid}")
        print("â¬†ï¸ Sending Starter Response\n")
        return {
            "session_id": new_sid,
            "reply": starter,
            "books": [],
            "follow_up": True,
        }

    # Ensure we have a session id
    sid = get_session(req.session_id)
    session = SESSIONS[sid]
    touch_session(sid)

    print(f"ğŸŸ¡ [Session Active] session_id={sid}")
    print(f"ğŸ§¾ Current user_prefs: {list(session['user_prefs'].values())}")
    print(f"ğŸ•“ Last active: {time.strftime('%X', time.localtime(session['last_active']))}")

    # If no message provided, just return session id
    if not req.message:
        print("âšª No message provided â€” returning Ready response.\n")
        return {"session_id": sid, "reply": "Ready.", "books": [], "follow_up": True}

    user_text = req.message.strip()
    session["conversation_history"].append({"role": "user", "content": user_text})
    pref_key = f"pref_{len(session['user_prefs']) + 1}"
    session["user_prefs"][pref_key] = user_text

    try:
        lang = "ar" if detect(user_text) == "ar" else "en"
    except:
        lang = "en"
    print(f"ğŸŒ Detected language: {lang}")
    normalized_lang = normalize_language(lang)
    print(f"ğŸŒ Detected language: {lang} â†’ Normalized: {normalized_lang}")

    trigger_terms = ["recommend", "suggest", "surprise", "Ø§Ù‚ØªØ±Ø­", "Ø±Ø´Ø­", "Ù†ØµÙŠØ­Ø©"]
    need_recommend = any(t in user_text.lower() for t in trigger_terms) or len(session["user_prefs"]) >= 4
    
    last_assistant_msg = None
    if session["conversation_history"]:
        for msg in reversed(session["conversation_history"]):
            if msg["role"] == "assistant":
                last_assistant_msg = msg["content"]
                break

    is_language_response = (
        last_assistant_msg and 
        any(phrase in last_assistant_msg for phrase in ["Ø£ÙŠ Ù„ØºØ© ØªÙØ¶Ù„ Ø£Ù† ØªÙ‚Ø±Ø£ Ø¨Ù‡Ø§ Ø§Ù„ÙƒØªØ¨ØŸ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ù… Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŸ", "Which language do you prefer to read books in? Arabic or English?"]) and
        any(word in user_text.lower() for word in ["english", "eng", "en", "Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©", "Ø§Ù†Ø¬Ù„ÙŠØ²ÙŠ", "Ø§Ù†Ø¬Ù„Ø´", "Ø¹Ø±Ø¨ÙŠ", "Ø¹Ø±Ø¨ÙŠØ©", "arabic", "ar"])
    )

    if is_language_response and "preferred_reading_lang" not in session:
        print("ğŸŸ¡ [Stage] Processing language preference...")
        
        # ØªØ­Ø¯ÙŠØ¯ Ù„ØºØ© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ÙØ¶Ù„Ø© Ù…Ù† Ø±Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        if any(word in user_text.lower() for word in ["english", "eng", "en", "Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©", "Ø§Ù†Ø¬Ù„ÙŠØ²ÙŠ", "Ø§Ù†Ø¬Ù„Ø´"]):
            session["preferred_reading_lang"] = "en"
            if normalized_lang == "ar":
                confirmation = "Ø­Ø³Ù†Ø§Ù‹ØŒ Ø³Ø£ÙˆØµÙŠ Ù„Ùƒ Ø¨ÙƒØªØ¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ğŸ“š"
            else:
                confirmation = "Great! I'll recommend books in English ğŸ“š"
        else:
            session["preferred_reading_lang"] = "ar"
            if normalized_lang == "ar":
                confirmation = "Ø­Ø³Ù†Ø§Ù‹ØŒ Ø³Ø£ÙˆØµÙŠ Ù„Ùƒ Ø¨ÙƒØªØ¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ğŸ“š"
                follow_up = "Ù‡Ù„ ØªØ±ÙŠØ¯ Ø£Ù† Ø£Ø¨Ø¯Ø£ Ø§Ù„ØªÙˆØµÙŠØ©ØŸ"

            else:
                confirmation = "Great! I'll recommend books in Arabic ğŸ“š"
                follow_up = "Should I start the recommendation?"

        print(f"ğŸ“– User preferred reading language: {session['preferred_reading_lang']}")
        full_reply = f"{confirmation} {follow_up}"
        session["conversation_history"].append({"role": "assistant", "content": full_reply})
        touch_session(sid)

        response = {"session_id": sid, "reply": full_reply, "books": [], "follow_up": True}

        print("\nğŸ”µ --- Outgoing Response (Language Confirmation) ---")
        print(json.dumps(response, indent=2, ensure_ascii=False))
        print("------------------------------------------------\n")

        return response

    # 2. Ø«Ù… ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙˆØµÙ„Ù†Ø§ Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªÙˆØµÙŠØ© ÙˆÙ„ÙƒÙ† Ù„Ù… Ù†Ø³Ø£Ù„ Ø¹Ù† Ø§Ù„Ù„ØºØ© Ø¨Ø¹Ø¯
    if need_recommend and "preferred_reading_lang" not in session:
        print("ğŸŸ¡ [Stage] Asking for preferred reading language...")
        
        if normalized_lang == "ar":
            question = "Ø£ÙŠ Ù„ØºØ© ØªÙØ¶Ù„ Ø£Ù† ØªÙ‚Ø±Ø£ Ø¨Ù‡Ø§ Ø§Ù„ÙƒØªØ¨ØŸ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ù… Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŸ"
        else:
            question = "Which language do you prefer to read books in? Arabic or English?"
        
        session["conversation_history"].append({"role": "assistant", "content": question})
        touch_session(sid)

        response = {"session_id": sid, "reply": question, "books": [], "follow_up": True}

        print("\nğŸ”µ --- Outgoing Response (Language Question) ---")
        print(json.dumps(response, indent=2, ensure_ascii=False))
        print("------------------------------------------------\n")

        return response

    # 3. Ø«Ù… Ø§Ù„ØªÙˆØµÙŠØ© Ø¨Ø¹Ø¯ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„ØºØ©
    if need_recommend and "preferred_reading_lang" in session:
        print("ğŸŸ£ [Stage] Generating recommendations...")
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„ØºØ© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ÙØ¶Ù„Ø© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù„ØºØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        reading_lang = session["preferred_reading_lang"]
        normalized_reading_lang = normalize_language(reading_lang)
        print(f"ğŸ“– Using preferred reading language: {reading_lang} â†’ Normalized: {normalized_reading_lang}")

        full_query = " ; ".join(session["user_prefs"].values())
        print(f"ğŸ“‹ Full user query: {full_query}")
        
        best_books = find_top_k(full_query, k=TOP_K)
        print(f"ğŸ“š Found {len(best_books)} similar books")
        
        for b in best_books:
            ensure_cover(b)
        
        print("books:", best_books)
        
        # Debug info
        print(f"ğŸ” Language Debug:")
        print(f"   User reading lang: {reading_lang} â†’ Normalized: {normalized_reading_lang}")
        print(f"   Book languages: {[b.get('language') for b in best_books]}")
        print(f"   Normalized book languages: {[normalize_language(b.get('language', '')) for b in best_books]}")
        
        matched_books = []
        books_block = ""
        for b in best_books:
            book_lang_normalized = normalize_language(b.get('language', ''))
            if book_lang_normalized == normalized_reading_lang:
                print(f"âœ… Book language matched: {b.get('language', '')} â†’ User reading lang: {normalized_reading_lang}") 
                books_block += f"Title: {b['title']}\nAuthor: {b.get('authors','')}\nSummary: {b.get('short_summary','')}\n\n"
                matched_books.append(b)
            else:
                print(f"âŒ Book language NOT matched: {b.get('language', '')} â†’ User wanted: {normalized_reading_lang}")
        
        # âš ï¸ ØµØ­Ø­ Ø§Ù„Ø®Ø·Ø£ Ù‡Ù†Ø§ - Ø§Ø³ØªØ®Ø¯Ù… reading_lang Ø¨Ø¯Ù„ lang
        prompt = f"""
You are a helpful librarian. The user described preferences: {full_query}.
Below are candidate books from {books_block}. For each book, write one short line in {normalized_lang} explaining why it matches the user's preferences. Keep the response focused only on the books and their reasons.
start the recommendation with a short introductory sentence without hello or welcomeing .
Reply in {normalized_lang} don't suggest not existing book here in the {books_block}.
"""
        print("ğŸ¤– Sending prompt to LLM for recommendation explanation...")
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}]
        )
        reply = resp.choices[0].message.content
        print("âœ… [LLM Reply Received]")

        # âš ï¸ ØµØ­Ø­ Ø§Ù„Ø®Ø·Ø£ Ù‡Ù†Ø§ - Ø§Ø³ØªØ®Ø¯Ù… matched_books Ø¨Ø¯Ù„ best_books
        response = {
            "session_id": sid,
            "reply": reply,
            "books": matched_books,  # â¬…ï¸ Ù‡Ù†Ø§ Ø§Ù„ØªØµØ­ÙŠØ­
            "follow_up": False,
        }

        print("\nğŸ”µ --- Outgoing Response (Recommendation) ---")
        print(json.dumps(response, indent=2, ensure_ascii=False))
        print("------------------------------------------------\n")

        return response

    # 4. ÙˆØ£Ø®ÙŠØ±Ø§Ù‹ follow-up question
    else:
        print("ğŸŸ¢ [Stage] Generating follow-up question...")
        history_text = "\n".join([f"{h['role']}: {h['content']}" for h in session["conversation_history"]])

        prompt = f"""
You are a friendly, curious librarian. Ask one short, natural follow-up question that helps select a book.
Do not ask more than one question. Keep it specific and not repetitive.
If the user seems to have already given genre/mood/length or examples, ask about details like favorite authors, pace, or setting.
Respond in {lang}.
Conversation:
{history_text}
"""
        print("ğŸ¤– Sending prompt to LLM for follow-up question...")
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}]
        )
        reply = resp.choices[0].message.content
        print("âœ… [LLM Reply Received]")

        session["conversation_history"].append({"role": "assistant", "content": reply})
        touch_session(sid)

        response = {"session_id": sid, "reply": reply, "books": [], "follow_up": True}

        print("\nğŸ”µ --- Outgoing Response (Follow-up) ---")
        print(json.dumps(response, indent=2, ensure_ascii=False))
        print("------------------------------------------------\n")

        return response